<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>SEM train with Deep Neural Netwok (DNN) models — SEMdnn • SEMdeep</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="SEM train with Deep Neural Netwok (DNN) models — SEMdnn"><meta name="description" content="The function builds four Deep Neural Networks (DNN) models based
on the topological structure of the input graph using the 'torch' language.
The torch package is native to R, so it's computationally efficient
and the installation is very simple, as there is no need to install Python
or any other API, and DNNs can be trained on CPU, GPU and MacOS GPUs.
In order to install torch please follow these steps:
install.packages(&quot;torch&quot;)
library(torch)
install_torch(reinstall = TRUE)
For setup GPU or if you have problems installing torch package, check out the
installation
help from the torch developer."><meta property="og:description" content="The function builds four Deep Neural Networks (DNN) models based
on the topological structure of the input graph using the 'torch' language.
The torch package is native to R, so it's computationally efficient
and the installation is very simple, as there is no need to install Python
or any other API, and DNNs can be trained on CPU, GPU and MacOS GPUs.
In order to install torch please follow these steps:
install.packages(&quot;torch&quot;)
library(torch)
install_torch(reinstall = TRUE)
For setup GPU or if you have problems installing torch package, check out the
installation
help from the torch developer."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">SEMdeep</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/BarbaraTarantino/SEMdeep/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>SEM train with Deep Neural Netwok (DNN) models</h1>
      <small class="dont-index">Source: <a href="https://github.com/BarbaraTarantino/SEMdeep/blob/HEAD/R/SEMdnn.R" class="external-link"><code>R/SEMdnn.R</code></a></small>
      <div class="d-none name"><code>SEMdnn.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>The function builds four Deep Neural Networks (DNN) models based
on the topological structure of the input graph using the 'torch' language.
The <span class="pkg">torch</span> package is native to R, so it's computationally efficient
and the installation is very simple, as there is no need to install Python
or any other API, and DNNs can be trained on CPU, GPU and MacOS GPUs.</p>
<p>In order to install <span class="pkg">torch</span> please follow these steps:</p>
<p><code>install.packages("torch")</code></p>
<p><code><a href="https://torch.mlverse.org/docs" class="external-link">library(torch)</a></code></p>
<p><code>install_torch(reinstall = TRUE)</code></p>
<p>For setup GPU or if you have problems installing <span class="pkg">torch</span> package, check out the
<a href="https://torch.mlverse.org/docs/articles/installation.html/" class="external-link">installation</a>
help from the torch developer.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">SEMdnn</span><span class="op">(</span></span>
<span>  <span class="va">graph</span>,</span>
<span>  <span class="va">data</span>,</span>
<span>  outcome <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  algo <span class="op">=</span> <span class="st">"layerwise"</span>,</span>
<span>  hidden <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10L</span>, <span class="fl">10L</span>, <span class="fl">10L</span><span class="op">)</span>,</span>
<span>  link <span class="op">=</span> <span class="st">"selu"</span>,</span>
<span>  bias <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  dropout <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>  validation <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  alpha <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  lr <span class="op">=</span> <span class="fl">0.01</span>,</span>
<span>  batchsize <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  burnin <span class="op">=</span> <span class="fl">30</span>,</span>
<span>  thr <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  nboot <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  patience <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  device <span class="op">=</span> <span class="st">"cpu"</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-graph">graph<a class="anchor" aria-label="anchor" href="#arg-graph"></a></dt>
<dd><p>An igraph object.</p></dd>


<dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>A matrix with rows corresponding to subjects, and columns
to graph nodes (variables).</p></dd>


<dt id="arg-outcome">outcome<a class="anchor" aria-label="anchor" href="#arg-outcome"></a></dt>
<dd><p>A character vector (as.factor) of labels for a categorical
output (target). If NULL (default), the categorical output (target) will
not be considered.</p></dd>


<dt id="arg-algo">algo<a class="anchor" aria-label="anchor" href="#arg-algo"></a></dt>
<dd><p>A character value, indicating the DNN algorithm: "nodewise",
"layerwise" (default), "structured", or "neuralgraph" (see details).</p></dd>


<dt id="arg-hidden">hidden<a class="anchor" aria-label="anchor" href="#arg-hidden"></a></dt>
<dd><p>hidden units in layers; the number of layers corresponds with
the length of the hidden units. As a default, hidden = c(10L, 10L, 10L).</p></dd>


<dt id="arg-link">link<a class="anchor" aria-label="anchor" href="#arg-link"></a></dt>
<dd><p>A character value describing the activation function to use, which
might be a single length or be a vector with many activation functions assigned
to each layer. As a default, link = "selu".</p></dd>


<dt id="arg-bias">bias<a class="anchor" aria-label="anchor" href="#arg-bias"></a></dt>
<dd><p>A logical vector, indicating whether to employ biases in the layers,
which can be either vectors of logicals for each layer (number of hidden layers
+ 1 (final layer)) or of length one.  As a default, bias = TRUE.</p></dd>


<dt id="arg-dropout">dropout<a class="anchor" aria-label="anchor" href="#arg-dropout"></a></dt>
<dd><p>A numerical value for the dropout rate, which is the probability
that a node will be excluded from training.  As a default, dropout = 0.</p></dd>


<dt id="arg-loss">loss<a class="anchor" aria-label="anchor" href="#arg-loss"></a></dt>
<dd><p>A character value specifying the at which the network should
be optimized. For regression problem used in SEMdnn(), the user can specify:
(a) "mse" (mean squared error), "mae" (mean absolute error), or "nnl"
(negative log-likelihood). As a default, loss = "mse".</p></dd>


<dt id="arg-validation">validation<a class="anchor" aria-label="anchor" href="#arg-validation"></a></dt>
<dd><p>A numerical value indicating the proportion of the data set
that should be used as a validation set (randomly selected, default = 0).</p></dd>


<dt id="arg-lambda">lambda<a class="anchor" aria-label="anchor" href="#arg-lambda"></a></dt>
<dd><p>A numerical value, indicating the strength of the regularization,
\(\lambda\)(L1 + L2) for lambda penalty (default = 0).</p></dd>


<dt id="arg-alpha">alpha<a class="anchor" aria-label="anchor" href="#arg-alpha"></a></dt>
<dd><p>A numerical value, add L1/L2 regularization into the training.
Set the alpha parameter for each layer to (1-\(\alpha\))L1 + \(\alpha\)L2.
It must fall between 0 and 1 (default = 0.5).</p></dd>


<dt id="arg-optimizer">optimizer<a class="anchor" aria-label="anchor" href="#arg-optimizer"></a></dt>
<dd><p>A character value, indicating the optimizer to use for
training the network. The user can specify: "adam" (ADAM algorithm), "adagrad"
(adaptive gradient algorithm), "rmsprop" (root mean squared propagation),
"rprop” (resilient backpropagation), "sgd" (stochastic gradient descent).
As a default, optimizer = "adam".</p></dd>


<dt id="arg-lr">lr<a class="anchor" aria-label="anchor" href="#arg-lr"></a></dt>
<dd><p>A numerical value, indicating the learning rate given to the optimizer
(default = 0.01).</p></dd>


<dt id="arg-batchsize">batchsize<a class="anchor" aria-label="anchor" href="#arg-batchsize"></a></dt>
<dd><p>Number of samples that are used to calculate one learning rate
step (default = 1/10 of the training data).</p></dd>


<dt id="arg-burnin">burnin<a class="anchor" aria-label="anchor" href="#arg-burnin"></a></dt>
<dd><p>Training is aborted if the trainings loss is not below the baseline
loss after burnin epochs (default = 30).</p></dd>


<dt id="arg-thr">thr<a class="anchor" aria-label="anchor" href="#arg-thr"></a></dt>
<dd><p>A numeric value [0-1] indicating the threshold to apply to the
Olden's connection weights to color the graph. If thr = NULL (default), the
threshold is set to thr = 0.5*max(abs(connection weights)).</p></dd>


<dt id="arg-nboot">nboot<a class="anchor" aria-label="anchor" href="#arg-nboot"></a></dt>
<dd><p>number of bootstrap samples that will be used to compute cheap
(lower, upper) CIs for all input variable weights. As a default, nboot = 0.</p></dd>


<dt id="arg-epochs">epochs<a class="anchor" aria-label="anchor" href="#arg-epochs"></a></dt>
<dd><p>A numerical value indicating the epochs during which the training
is conducted (default = 100).</p></dd>


<dt id="arg-patience">patience<a class="anchor" aria-label="anchor" href="#arg-patience"></a></dt>
<dd><p>A numeric value, training will terminate if the loss
increases over a predetermined number of consecutive epochs and apply validation
loss when available. Default patience = 100, no early stopping is applied.</p></dd>


<dt id="arg-device">device<a class="anchor" aria-label="anchor" href="#arg-device"></a></dt>
<dd><p>A character value describing the CPU/GPU device ("cpu", "cuda", "mps")
on which the  neural network should be trained on. As a default, device = "cpu".</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>The training loss values of the DNN model are displayed as output,
comparing the training, validation and baseline in the last epoch (default = FALSE).</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Currently ignored.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>An S3 object of class "DNN" is returned. It is a list of 5 objects:</p><ol><li><p>"fit", a list of DNN model objects, including: the estimated covariance
matrix (Sigma), the estimated model errors (Psi), the fitting indices (fitIdx),
and the parameterEstimates, i.e., the data.frame of Olden's connection weights.</p></li>
<li><p>"gest", the data.frame of estimated connection weights (parameterEstimates)
of outcome levels, if outcome != NULL.</p></li>
<li><p>"model", a list of all MLP network models fitted by torch.</p></li>
<li><p>"graph", the induced DAG of the input graph mapped on data variables.
The DAG is colored based on the Olden's connection weights (W), if abs(W) &gt; thr
and W &lt; 0, the edge is inhibited and it is highlighted in blue; otherwise, if
abs(W) &gt; thr and W &gt; 0, the edge is activated and it is highlighted in red.
If the outcome vector is given, nodes with absolute connection weights summed
over the outcome levels, i.e. sum(abs(W[outcome levels])) &gt; thr, will be
highlighted in pink.</p></li>
<li><p>"data", input data subset mapping graph nodes.</p></li>
</ol></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Four Deep Neural Networks (DNNs) are trained with <code>SEMdnn()</code>.</p>
<p>If algo = "nodewise", a set of DNN models is performed equation-by-equation
(r=1,...,R) times, where R is the number of response (outcome) variables (i.e.,
nodes in the input graph with non-zero incoming connectivity) and predictor (input)
variables are nodes with a direct edge to the outcome nodes, as poposed by various
authors in causal discovery methods (see Zheng et al, 2020). Note, that model
learning can be time-consuming for large graphs and large R outcomes.</p>
<p>If algo = "layerwise" (default), a set of DNN models is defined based on the topological
layer structure (j=1,…,L) from sink to source nodes of the input graph. In each
iteration, the response (output) variables, y are the nodes in the j=1,...,(L-1)
layer, and the predictor (input) variables, x are the nodes belonging to successive:
(j+1),...,L layers, which are linked with a direct edge to the response variables
(see Grassi &amp; Tarantino, 2025).</p>
<p>If algo = "structured", a Structured Neural Network (StrNN) is defined with input
and output units equal to D, the number of the nodes. The algorithm uses the
prior knowledge of the input graph to build the neural network architecture via a
per-layer masking of the neural weights (i.e., W1 * M1, W2 * M2, ..., WL *ML), with
the constraint that (W1 * M1) x (W2 * M2) x ... x (WL * ML) = A, where A is the
adjacency matrix of the input graph (see Chen et al, 2023).</p>
<p>If algo = "neuralgraph", a Neural Graphical Model (NGM) is generated. As StrNN input
and output units are equal to D, the number of the nodes. The prior knowledge of the
input graph is used to compute the product of the absolute value of the neural weights
(i.e., W = |W1| x |W2| x ... x |WL|), under the constraint that log(W * Ac) = 0,
where Ac represents the complement of the adjacency matrix A of input graph, which
essentially replaces 0 by 1 and vice-versa (see Shrivastava &amp; Chajewska, 2023).</p>
<p>Each DNN model (R for "nodewise", L&lt;R for "layerwise", and 1 for "structured" and
"neuralgraph") is a Multilayer Perceptron (MLP) network, where every neuron node
is connected to every other neuron node in the hidden layer above and every other
hidden layer below. Each neuron's value is determined by calculating a weighted
summation of its outputs from the hidden layer before it, and then applying an
activation function.  The calculated value of every neuron is used as the input
for the neurons in the layer below it, until the output layer is reached.</p>
<p>If boot != 0, the function will implement the cheap bootstrapping proposed by
Lam (2002) to generate uncertainties (i.e., bootstrap <code>90%CIs</code>) for DNN
parameters. Bootstrapping can be enabled by setting a small number (1 to 10) of
bootstrap samples. Note, however, that the computation can be time-consuming for
massive DNNs, even with cheap bootstrapping!</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Zheng, X., Dan, C., Aragam, B., Ravikumar, P., Xing E. (2020). Learning sparse
nonparametric dags. International conference on artificial intelligence and statistics,
PMLR, 3414-3425. https://doi.org/10.48550/arXiv.1909.13189</p>
<p>Grassi, M., Tarantino, B. (2025). SEMdag: Fast learning of Directed Acyclic Graphs via
node or layer ordering. PLoS ONE 20(1): e0317283. https://doi.org/10.1371/journal.pone.0317283</p>
<p>Chen A., Shi, R.I., Gao, X., Baptista, R., Krishnan, R.G. (2023). Structured neural
networks for density estimation and causal inference. Advances in Neural Information
Processing Systems, 36, 66438-66450. https://doi.org/10.48550/arXiv.2311.02221</p>
<p>Shrivastava, H., Chajewska, U. (2023). Neural graphical models. In European Conference
on Symbolic and Quantitative Approaches with Uncertainty (pp. 284-307). Cham: Springer
Nature Switzerland. https://doi.org/10.48550/arXiv.2210.00453</p>
<p>Lam, H. (2022). Cheap Bootstrap for Input Uncertainty Quantification. Winter Simulation
Conference (WSC), Singapore, 2022, pp. 2318-2329. https://doi.org/10.1109/WSC57314.2022.10015362</p>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Mario Grassi <a href="mailto:mario.grassi@unipv.it">mario.grassi@unipv.it</a></p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_is_installed.html" class="external-link">torch_is_installed</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">{</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># load ALS data</span></span></span>
<span class="r-in"><span><span class="va">ig</span><span class="op">&lt;-</span> <span class="va">alsData</span><span class="op">$</span><span class="va">graph</span></span></span>
<span class="r-in"><span><span class="va">data</span><span class="op">&lt;-</span> <span class="va">alsData</span><span class="op">$</span><span class="va">exprs</span></span></span>
<span class="r-in"><span><span class="va">data</span><span class="op">&lt;-</span> <span class="fu">transformData</span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">$</span><span class="va">data</span></span></span>
<span class="r-in"><span><span class="va">group</span><span class="op">&lt;-</span> <span class="va">alsData</span><span class="op">$</span><span class="va">group</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#...with train-test (0.5-0.5) samples</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">train</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="fl">0.5</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co">#ncores&lt;- parallel::detectCores(logical = FALSE)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">start</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">dnn0</span><span class="op">&lt;-</span> <span class="fu">SEMdnn</span><span class="op">(</span><span class="va">ig</span>, <span class="va">data</span><span class="op">[</span><span class="va">train</span>, <span class="op">]</span>, algo <span class="op">=</span> <span class="st">"layerwise"</span>,</span></span>
<span class="r-in"><span>      hidden <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">10</span>,<span class="fl">10</span><span class="op">)</span>, link <span class="op">=</span> <span class="st">"selu"</span>, bias <span class="op">=</span> <span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>      nboot <span class="op">=</span> <span class="fl">0</span>, epochs <span class="op">=</span> <span class="fl">32</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">end</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">end</span><span class="op">-</span><span class="va">start</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#str(dnn0, max.level=2)</span></span></span>
<span class="r-in"><span><span class="va">dnn0</span><span class="op">$</span><span class="va">fit</span><span class="op">$</span><span class="va">fitIdx</span></span></span>
<span class="r-in"><span><span class="fu">parameterEstimates</span><span class="op">(</span><span class="va">dnn0</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">gplot</span><span class="op">(</span><span class="va">dnn0</span><span class="op">$</span><span class="va">graph</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu">E</span><span class="op">(</span><span class="va">dnn0</span><span class="op">$</span><span class="va">graph</span><span class="op">)</span><span class="op">$</span><span class="va">color</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#...with source nodes -&gt; graph layer structure -&gt; sink nodes</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#Topological layer (TL) ordering</span></span></span>
<span class="r-in"><span><span class="va">K</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">12</span>,  <span class="fl">5</span>,  <span class="fl">3</span>,  <span class="fl">2</span>,  <span class="fl">1</span>,  <span class="fl">8</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">K</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="va">K</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">K</span><span class="op">)</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>;<span class="va">K</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">ig1</span><span class="op">&lt;-</span> <span class="fu"><a href="mapGraph.html">mapGraph</a></span><span class="op">(</span><span class="va">ig</span>, type<span class="op">=</span><span class="st">"source"</span><span class="op">)</span>; <span class="fu">gplot</span><span class="op">(</span><span class="va">ig1</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">start</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">dnn1</span><span class="op">&lt;-</span> <span class="fu">SEMdnn</span><span class="op">(</span><span class="va">ig1</span>, <span class="va">data</span><span class="op">[</span><span class="va">train</span>, <span class="op">]</span>, algo <span class="op">=</span> <span class="st">"layerwise"</span>,</span></span>
<span class="r-in"><span>      hidden <span class="op">=</span> <span class="fl">5</span><span class="op">*</span><span class="va">K</span>, link <span class="op">=</span> <span class="st">"selu"</span>, bias <span class="op">=</span> <span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>    nboot <span class="op">=</span> <span class="fl">0</span>, epochs <span class="op">=</span> <span class="fl">32</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">end</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">end</span><span class="op">-</span><span class="va">start</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#Visualization of the neural network structure</span></span></span>
<span class="r-in"><span><span class="fu"><a href="nplot.html">nplot</a></span><span class="op">(</span><span class="va">dnn1</span>, hidden <span class="op">=</span> <span class="fl">5</span><span class="op">*</span><span class="va">K</span>, bias <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#str(dnn1, max.level=2)</span></span></span>
<span class="r-in"><span><span class="va">dnn1</span><span class="op">$</span><span class="va">fit</span><span class="op">$</span><span class="va">fitIdx</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">dnn1</span><span class="op">$</span><span class="va">fit</span><span class="op">$</span><span class="va">Psi</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">parameterEstimates</span><span class="op">(</span><span class="va">dnn1</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">gplot</span><span class="op">(</span><span class="va">dnn1</span><span class="op">$</span><span class="va">graph</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu">E</span><span class="op">(</span><span class="va">dnn1</span><span class="op">$</span><span class="va">graph</span><span class="op">)</span><span class="op">$</span><span class="va">color</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#...with a categorical outcome</span></span></span>
<span class="r-in"><span><span class="va">outcome</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">group</span> <span class="op">==</span> <span class="fl">0</span>, <span class="st">"control"</span>, <span class="st">"case"</span><span class="op">)</span><span class="op">)</span>; <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span> </span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">start</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">dnn2</span><span class="op">&lt;-</span> <span class="fu">SEMdnn</span><span class="op">(</span><span class="va">ig</span>, <span class="va">data</span><span class="op">[</span><span class="va">train</span>, <span class="op">]</span>, <span class="va">outcome</span><span class="op">[</span><span class="va">train</span><span class="op">]</span>, algo <span class="op">=</span> <span class="st">"layerwise"</span>,</span></span>
<span class="r-in"><span>      hidden <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">10</span>,<span class="fl">10</span><span class="op">)</span>, link <span class="op">=</span> <span class="st">"selu"</span>, bias <span class="op">=</span> <span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>      nboot <span class="op">=</span> <span class="fl">0</span>, epochs <span class="op">=</span> <span class="fl">32</span>,  verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">end</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">end</span><span class="op">-</span><span class="va">start</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#str(dnn2, max.level=2)</span></span></span>
<span class="r-in"><span><span class="va">dnn2</span><span class="op">$</span><span class="va">fit</span><span class="op">$</span><span class="va">fitIdx</span></span></span>
<span class="r-in"><span><span class="fu">parameterEstimates</span><span class="op">(</span><span class="va">dnn2</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">gplot</span><span class="op">(</span><span class="va">dnn2</span><span class="op">$</span><span class="va">graph</span><span class="op">)</span> </span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu">E</span><span class="op">(</span><span class="va">dnn2</span><span class="op">$</span><span class="va">graph</span><span class="op">)</span><span class="op">$</span><span class="va">color</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu">V</span><span class="op">(</span><span class="va">dnn2</span><span class="op">$</span><span class="va">graph</span><span class="op">)</span><span class="op">$</span><span class="va">color</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Conducting the nonparanormal transformation via shrunkun ECDF...done.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Running SEM model via DNN...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 1 : z10452 z84134 z836 z4747 z4741 z4744 z79139 z5530 z5532 z5533 ...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.3830909       Inf 0.9875000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 2 : z842 z1432 z5600 z5603 z6300 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.5071168       Inf 0.9875000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 3 : z54205 z5606 z5608 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    train      val     base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.574218      Inf 0.987500 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 4 : z596 z4217 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.7870750       Inf 0.9875001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 5 : z1616 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.8662748       Inf 0.9875001 </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span>  done.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> DNN solver ended normally after 160 iterations</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span>  logL:-40.972362  srmr:0.153875</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Time difference of 13.73143 secs</span>
<span class="r-plt img"><img src="SEMdnn-1.png" alt="" width="700" height="433"></span>
<span class="r-plt img"><img src="SEMdnn-2.png" alt="" width="700" height="433"></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Running SEM model via DNN...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 1 : z10452 z84134 z836 z4747 z4741 z4744 z79139 z5530 z5532 z5533 ...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    train      val     base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.464351      Inf 0.987500 </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span>  done.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> DNN solver ended normally after 32 iterations</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span>  logL:-21.207845  srmr:0.164237</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Time difference of 3.402986 secs</span>
<span class="r-plt img"><img src="SEMdnn-3.png" alt="" width="700" height="433"></span>
<span class="r-plt img"><img src="SEMdnn-4.png" alt="" width="700" height="433"></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Running SEM model via DNN...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 1 : zcase zcontrol </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>       train         val        base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.007218269         Inf 0.987500012 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 2 : z10452 z84134 z836 z4747 z4741 z4744 z79139 z5530 z5532 z5533 ...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.4185528       Inf 0.9875000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 3 : z842 z1432 z5600 z5603 z6300 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.5245557       Inf 0.9875000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 4 : z54205 z5606 z5608 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.5877876       Inf 0.9875000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 5 : z596 z4217 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.7903771       Inf 0.9875001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> layer 6 : z1616 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     train       val      base </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.8544232       Inf 0.9875001 </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span>  done.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> DNN solver ended normally after 192 iterations</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span>  logL:-40.890996  srmr:0.167383</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Time difference of 17.33236 secs</span>
<span class="r-plt img"><img src="SEMdnn-5.png" alt="" width="700" height="433"></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  pink white </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     5    26 </span>
<span class="r-in"><span><span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Mario Grassi, Barbara Tarantino.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

